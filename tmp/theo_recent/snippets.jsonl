{"id": "p2aea9dytpE", "title": "Software engineering is dead now", "snippet": "I'm sure you've all seen the meme. We're 6 months away from AI taking our jobs as developers forever. And while this is a meme that we've been saying for years, I'm starting to really feel it. There have just been so many signals that things are actually changing now. From baby Keem using OpenClaw to the top G-Talking [&nbsp;__&nbsp;] on it to Cloudflare rewriting Nex.js JS in a week using AI to CEOs that barely even code building whole apps from scratch cloning billion-dollar companies in just a few days to Jack the original CEO of Twitter laying off 40% of his employees at Block even though they're profitable and growing. This is this is terrifying. We are there now. I didn't know what this would look like or how it would feel, but it's happening now. It's very clear it is happening now. And I have a lot of thoughts about that. Mostly in a very privileged position here where at least by the looks of it, media doesn't seem to be going anywhere. But that doesn't mean I don't talk to engineers every day and that I don't have hundreds of y'all in my DMs and talking to me across every possible imaginable method telling me just how screwed things are right now. And there is hope. There are places this can go that are good. But right now, the dev world is about to change. Normally, I would do a joke here about how I need ads because I'm not getting paid to write code anymore. But honestly, things are scary enough right now. It feels a bit inappropriate. So, just know I have to get my team paid. So, we'll do a quick break and then we'll dive in. Going to be real with you guys. I'm vibe coding a bit close to the sun lately. We're shipping so much code for all the projects we're working on and I would probably be shipping a lot more bugs if today's sponsor wasn't a thing. Code Rabbit has reviewed pretty much every line of code I've written in the past few months and it has prevented so many bugs from shipping. I've tried all of these AI code review tools with my team and this is the one my team chooses every single time. And I get why. It seems to just understand these complex code bases better than other tools, especially once you've used it for a bit because it has a good memory tool where it learns when you give it feedback. If you tell it, hey, this thing doesn't matter. It remembers and it won't comment on it in the future, which makes it really easy to reduce the noise and focus in on the signal. For a good example of that signal, here's a mistake that I never would have made in the good old days of handwriting code that an agent will gladly do. This directory should have been git ignored because it's a build directory, but somehow it snuck in here. I mean, I know how the agent had put it in the git ignore and now it's my problem. Being that this PR was like 3,000 lines of code, there's no world in which I would have bothered to read it well enough to catch this type of mistake. But Code Rabbit's more than happy to do that. Calling this out is a major potential issue and that this is a build directory that should have been ignored. Not only does it tell you exactly what's wrong, it gives you a prompt that you can copy paste, which is exactly what I did. I actually went through and found all of the issues that I agreed with in this feedback. Copy pasted the prompts, had them all fixed, and then we shipped. This is a big change in a real big repo, too. I'm working on a fun project they'll have more details on soon, I promise. That has everything from Rust and Swift code to TypeScript and Electron. So, uh, case in point, it's a rough codebase to work in, and I swear Code Rabbit's the only thing that seems to actually understand. It even caught a pretty novel bug with async cleanup operations with how we're abusing promises a little bit for our actual startup script that I don't think any other tool came close to catching. Whether or not you're using AI for code, you should absolutely use it for code review. If you're somehow not doing it yet, fix that today at soyv.link/code rabbit. It's literally just two clicks. There's a lot going on in the industry and I think this post from Jack is going to be a really good place to start from. Generally speaking, Jack tends to be a decent bit ahead of market trends at the very least 6 months to two years ahead overall. And it is incredibly rare for a company to do mass layoffs like this when they are currently in the process of growing and their revenue is going up and their profits are increasing. I have a lot of faith in Jack personally and I understand why he did this. It is his ultimate responsibility to make his business as successful as possible and as likely to succeed as possible. And right now there's a real risk of smaller teams moving faster and overtaking your position for cheaper. It's a silly example here, but I do want to talk about the product I just put out, lawn. I'm not here to try and sell this to you guys. The MR on it's like $350. It's not going to make real money. It's probably going to lose money, but it's a good example of where things are going. Lawn is an alternative to Frame.io. Frame.io IO is a video review platform kind of like doing code reviews and PRs but for video teams. It's how we have managed our video pipeline for a while. Whenever my editor FaZe finishes an edit, he would upload it onto Frame so that my team could review it. Whenever we have a new ad spot that needs to be approved by a brand, we put that up on Frame for them to approve. And every single time we just were watching it crumble. I swear I never went to frame.io without having to resign in cuz they broke off all the time. The share links were an absolute mess. I never knew when something got to one of the companies we were working with if they had responded or not. It was just a rough time. So I decided to make my own alternative largely just to explore the space and play around with these AI dev tools. I really didn't think we would ship this. I really didn't. But it just kept going. And I didn't sit and work on this full-time. Obviously I'm very busy. I have a company to run. I have a lot of other product that we're shipping. I have a channel to run. I employ like 15 people across all these surfaces. I don't have time to sit there and code for eight hours a day. If I did, I would guess this product would have taken me about a month or two to make and then a couple more months to refine and get all the core pieces in properly. I was able to build it in 2 weeks. I was able to build it in two weeks in the background as I did other things. That's crazy. I have not written a single line of code in this project. I've read a little bit of it. I structured a bunch of APIs and like core application logic stuff with the AI where I described how it should be structured, watched it write a proposal like that looks good, go use that everywhere. But I didn't write the code and it's not bad code. For proof, I actually decided to open source it, which is a weird decision for a bunch of reasons, but the main one that I think makes it so strange is that it makes it easy to clone and go build your own. So, it's already low revenue, but if somebody wants to be really cheap, they can go clone it themselves and host it, and then I get no revenue for it. But to be frank, that could have happened anyways. And that's what's so crazy. Ideas haven't been valuable for a long time. And I say that all the time. Ideas are cheap. Somehow ideas got more and less valuable at the same time. where dropping something novel and coming up with a good idea is really powerful now because the speed you can go from idea to usable product has never been lower. But it also means cloning someone else's product and idea is way more trivial than it's ever been. You might look at this and think, well video review can't be that big a market. Like you're only making what 350 a month isn't $350 a month. Well Frame.io got acquired by Adobe in 2021 for $1.3 billion. It took them years to build 1.3 bill and I was able to replicate the majority of the functionality part-time in an app that genuinely feels better to use in 2 weeks. Everything has changed. I don't care about your silly examples of co-pilot screwing up in a giant C codebase because I can rewrite that codebase in different tech in a week. Everything is different now. And it's not even slop. Like, yeah, the whole thing's vibe coded. Even the UI, even the background image, all AI generated,"}
{"id": "MWFyApldYDA", "title": "Trump actually threatened Anthropic (this is bad\u2026)", "snippet": "Believe it or not, I try to focus my content on the things I actually enjoy. The things I like doing, the things I like talking about, the things I'm building, all the things that bring me joy. But today, I have to do two things that bring me no joy at all. I have to talk about politics, and more importantly, I have to defend anthropic. I can't believe I've been put in this position. I really have tried to avoid anything politics related since I started this channel over four years ago. But when the US government starts sending threats to labs, I think it's time for me to jump in. The Pentagon has just threatened Anthropic, specifying that they must comply with the government's requests or they will be listed a supply chain threat. That's a pretty big deal, especially because we've never had any supply chain threat identified and marked that was a US company in the history of the United States. This is unprecedented action that, yes, is targeting a lab I happen to like making fun of a lot. But I hope we can all agree after we talk about this a bit that this is an absurd overreach that no free country should be able to do. I have a lot to say here from the original statement that the government put out in January to the followup from Shawn Parnell and the formal threats that are now being made to Anthropic to Daario's response that he just published a few hours ago where he seems to be rejecting these new policies being pushed on him. There's a lot to dive into here and I'm going to do my best to cover this in as reasonable and neutral a way as possible. But since this is such a highly political topic, finding a sponsor is going to be a bit tough. So, please give some love to whoever agreed to sponsor today's video. Hey, you. You're a pretty good engineer, right? I'm sure you've been in this position before. A user reports a bug. You know the exact code that caused it. You hop in the codebase, fix it, takes you what, five minutes max, and then you're stuck sitting there waiting for 30 plus minutes just so the build can complete for code you already know works. That's kind of insane, right? Well, today's sponsor Depot is here to make you feel way less insane. They're going to make your builds comically faster. Not like 20%, closer to like 20x. Postto saw 15x improvement in their build times. GRPC saw a 7x improvement. Zed saw 1.4x. Apache CFKA saw 3.1x. Even Mastadon saw 7x. The difference is crazy. They saved their customers almost 250,000 hours last week alone. Kind of crazy. There's a reason companies like Postto, Jane, Poolside, and more all use them. Hell, even Inference, you know, the company that does hardware provisioning, also uses them, too, which is nuts. It shows just how valuable what they built is. The depot cache and remote container builds are honestly kind of magical. You provision Docker images and then everyone on your team runs the depot command instead, and suddenly everything is way faster. Their cache is also incredible, and it's not limited to just their CI. Once you have something in their cache, your whole team can access it. So everything they do, even local builds, will be up to 10 times faster. So if you're tired of waiting for CI or you just want those Docker builds locally to be way faster, there's no better place than soy. And use code Theo for 75% off your first month. Let's start from the top. Memorandum for senior Pentagon Leadership Commanders of the Combatant Commands Defense Agency and Department of War Field Activities Directors. President Trump makes clear in executive order 14179. It is the policy of the United States to sustain and enhance America's global artificial intelligence dominance in order to promote human flourishing, economic competitiveness, and national security. This is the important piece here. In the national security domain, AI enabled warfare and AI enabled capability development will redefine the characteristics of military affairs over the next decade. This transformation is a race fueled by the accelerating pace of commercial AI innovation coming out of America's private sector. The United States military must build on its lead over our adversaries in integrating this technology established during President Trump's first term to make our war fighters more lethal and efficient. I I I hate to call out things like this cuz I I really am trying to not be political. I just want to cover the news here. But as a person who cares a lot about text formatting, copy, and how messages are presented, this piece here established during President Trump's first term, that sixword statement here shows that the whole point of this document is to perform the glazing process on Donald Trump. This is not a factual document that is meant to drive the nation forward. This is a political document meant to make a specific person feel good. this six-word piece would not be in a document for any other reason cuz Trump obviously had nothing to do with the creation of AI and the random chance that OpenAI happened to release chat GPT during Trump's term is not a meaningful piece of information other than to make Trump feel good. So, if there was any doubt for anybody, regardless of what side of the political aisle you're on, that this is just a political performance and not like something more meaningful, you're just wrong. There are six words here that prove you wrong. You cannot sit here and pretend that this is a good faith document and a good faith representation of things. You can say it doesn't matter. You can say, \"Well, yeah, they do things like that. I don't care though cuz they're doing what I want.\" That is fine. Just make sure you recognize that the difference between this and the difference between literal propaganda from China is the side of the world that they were inked on. Just need you guys to be factual here. Anyways, there's a lot of other little details in here. Most of it doesn't matter too much, but the AI model parody section is somewhat important. They directed the department to establish a delivery and integration cadence with AI vendors that enable the latest models to be deployed within 30 days of public release. And another totally not political statement, diversity, equity, and inclusion in social ideology have no place in the Department of War. So, we must not employ AI models which incorporate ideological tunings that interfere with their abilities to produce objectively truthful responses to user prompts. I've never heard about DEI more than I have during this admin. For what it is worth, they seem to think about it a lot. kind of nuts that a document about AI in war has a whole section about DEI, but that's where we're at in 2026. The important part here is that they direct that under the Secretary of War for acquisition and sustainment that they incorporate standard any lawful use language into any Department of War contract through which AI services are procured within 180 days. This means that if it is considered within the law, they should be able to use the models for it. That's the important piece. any safeguards that the models have to prevent things like killing people, making weapons, commanding weapons, scanning, surveillance, all of the things that a lot of these labs went out of their way to prevent any lawful use means that if the US declares it is within the law, then the model has to be allowed to kill people. Any safety guards that the models have in place have to be turned off for the government as long as the thing the government is doing is considered by the government to be within lawful use. One more important piece here is this idea that this is language they want to insert into any department of war contract through which AI services are procured. That means there's a really simple solution. If a company doesn't want to provide this to the government, they can choose to not. Historically, that's how free markets have worked. And for better or worse, and this is going to piss off all sides, I tend to like free markets. For the most part, they seem to balance things out okay when controlled and set up properly. Part of a free market is your ability to refuse customers. As a business owner, you should and do have a legal right to refuse customers based on the requests the customers make. A customer asks for a service you don't"}
{"id": "h8Pz51ZEW5U", "title": "They cut Node.js Memory in half \ud83d\udc40", "snippet": "Cut your Noode.js memory usage in half with this one simple trick. Okay, the cut the clickbait. This is actually a really cool topic. As I'm sure most of you all know, JavaScript is not exactly memory efficient. That's why we see hilarious things like cursor using 3.38 terab of RAM. JavaScript's a great language that does a lot of really cool things, but sadly memory management has never been one of the ones it is strongest with. Which is why I was really excited to see Matteo, who is one of the main contributors to Node, come out with a really cool post about how we cut Node memory usage in half with a oneline Docker image swap. To be clear, it's not one line of code changing here. A Docker image swap is a pretty big deal depending on where you're doing it, but the things that led to this performance win are genuinely really fascinating. Feel like most engineers don't appreciate just how much hard engineering work goes into JavaScript because they're quick to dismiss it as JavaScript. But V8 is one of the most complex and impressive projects ever built, and Node is not too far from it. The effort that's going into the C++ that is powering all of this stuff is hard to put into words, and some of it's really cool. I'm constantly surprised by how many hidden flags and features there are inside of V8 in Node that can fundamentally change the performance characteristics. This is one I did not know about that I think is really, really cool, and I can't wait to tell you all about it after a quick word from today's sponsor. If you don't have any users, you can skip this section, but for those who do, it's important to understand what they're actually doing with your service. And that's why today's sponsor is so important to me. HostG users are doing. I know this looks like an operating system, but they're actually a suite of product tools, things that you need to build real products. The main thing that you're going to use them for is analytics, and they are the best analytics provider. Open source, too, but it doesn't really matter cuz their hosting is absurdly cheap. Their free tier gives you a million events, 5,000 session recordings, a million requests to feature flags, 1,500 survey results, 100,000 errors and exceptions, and so much more. The data warehouse is one of the coolest parts, though, because you can integrate with other services. Integrations like Superbase and Stripe are super useful. Believe me, I spent way too much time in the Stripe dashboard. Post Hogs is significantly better, and it's like two clicks to set up. I was signing in to show you guys quick and I just their vibe is hilarious. Just the fact that they have a special Valentine's Day little thing is just that's how they are. Are you kidding? [gasps] Post hog. I want to just show off the data and your the vibes are immaculate. If you want a data company that doesn't take themselves too seriously, but is a serious contender for managing all of your data, look no further than soyb.link/postthog. Now, let's dive into how Matteo was able to cut Node's memory usage in half, as well as any potential negative side effects of this. V8, the C++ engine under the proverbial hood of JavaScript, includes a feature that many Node developers aren't familiar with. This feature, pointer compression, is a method for using smaller memory references in the JavaScript heap, reducing each pointer from 64 bits to 32 bits. The net is that you wind up using about 50% less memory for the same app without having to change any code. Pretty great, right? Well, almost. Node.js does not enable pointer compression by default for two historical reasons. I find this to be really interesting. There's been a couple times where this happened. One of the most famous ones was when I got in the fight with that person who claimed I was lying about performance differences between Verscell and Cloudflare because when he ran a trigonometry function in a loop, it performed better on Cloudflare than Verscell. The reason for that was actually [&nbsp;__&nbsp;] hilarious. Cloudflare doesn't run Node. Cloudflare runs their own V8-based engine. Verscell runs Node. It turns out there was a flag to do faster trig math that had been enabled by Cloudflare for their runtime of V8 that was not enabled by default in Node runtimes. Cloudflare were the ones who went and found this, fixed it, and got it upstreamed into Node itself, thereby killing the gap there. But that was just like one trigonometry function that didn't have the flag enabled to make it faster. Thanks, Pron, for that. But yeah, I still can't believe that my [&nbsp;__&nbsp;] posting and silly benchmarks ended up making Cloudflare 3 to 10 times faster for various workloads. So cool. And a lot of that just comes down to which flags are enabled and what values are set for them. People don't appreciate how much config there is in Node because none of us ever hit it. Like in Typescript, you go edit the TS config, but in Node, you don't really config anything. You just tell it to run a JavaScript file. But there are so many flags you can enable in the building and bundling of node that nobody ever touches and seeing into them with stuff like this is really fun. So let's see the historical reasons why this particular flag has not been enabled. So going through these reasons, first is the 4 gig cage limitation which means that enabling pointer compression required the entire node process to share a single 4 gig memory space between the main thread and all the worker threads. This is a significant issue. Cloudflare Ngalia partnered to solve this so that the cage could be per isolate, an individual instance of the V8 engine. To break this down a little bit for those who aren't as familiar with the worker model in JavaScript and V8, it is possible to spin up relatively safe isolates in V8 that have their own pool of memory. So, if I have some work going on in the main thread, like I'm trying to make sure when people hit buttons on the keyboard, something appears as quickly as possible, but I want to do something else that is complex computationally, like generate some UI or run some complex math. If you do that on the main thread, other inputs and other things the user is doing are going to be blocked by that background work. Workers are a way to effectively spin up another instance of the JS engine. It's not really a new instance. a sub isolate within it that has its own memory, its own runner, and can be run in parallel to what you're doing in the main thread. So that things happening in the worker don't block the main thread. But in order for that to work, it needs to have its own memory that it's operating against. You cannot share memory between a worker and the main thread. You have to pass events between the two. As a result of this complexity, a lot of people have just never built with workers. I don't really know many JavaScript developers that have used workers in the browser. I'm not talking about Cloudflare workers. talking about browser workers for other threads to prevent blocking main thread as you're doing things. I just don't know many who have used it that way. Cloudflare uses them very heavily. The reason the platform is called Cloudflare workers is because you don't get your own instance of V8 when you use Cloudflare. The V8 instance has workers spun up for every request. So the same way I could in the browser spin up a worker to do something else while the user is still using the site, Cloudflare has the one main V8 instance with tons of workers that are spun up in order to do these other things so that they can run on the same instance of V8 thereby massively reducing Cloudflare's costs for hosting and also allowing them to be as cheap as they are relatively speaking. And yes, Nean, web workers are the right term for the version for the web, but what the [&nbsp;__&nbsp;] would be called the ones in node if that was the case? The point I'm trying to make here is that Cloudflare has invested a lot in doing things to prevent weird memory characteristics in workers because they want this to work as well as possible for the stuff they are hosting. And the problem here was that the entire node process was sharing a single 4 gig memory space and whenever"}
{"id": "9iUd2Ik-bBI", "title": "My new app is really stupid (I wrote none of the code)", "snippet": "As you guys have probably seen in my recent videos, I've been vibe coding a bunch of stuff, but I haven't released any of it. Well, not yet. That changes now, though, because I just put out one of my favorite side projects that I've been working on for a bit. It was an idea I've had for months now, but I only just recently found the time to actually build it, and I couldn't be happier with what we've built. So, without further ado, I would love to reveal No, ignore that one. Quip slop. We can finally learn once and for all which AI is funniest. This is a game idea I had forever ago to take something like Quiplash, the game from Jackbox, and try to recreate it with AI. The flow is pretty simple. One model creates a prompt that the other two models have to respond to in a funny way. It can be a fill-in- thelank. It can be a question about a title for a thing. Just all sorts of funny prompts that are then meant to let the model make a funnier response. Two models are picked to give their responses and then all the other models vote and the winner gets a point and they are ranked in the leaderboard. We also just set it up so the viewers can vote, too. So, if you're watching on Twitch at twitch.tv/quipslop, you can vote as you go. This project has sent us down some pretty absurd paths, and this is not the first time I've tried filming this video. In fact, we are now 4 hours past the first time I tried to film this video. We have been in utter chaos now for hours, and I can't wait to break all of it down for you. From how we built this to what went wrong to how we scaled it to tens of thousands of users, all live on Twitch. But after seeing a preview of my open router bill, we're going to take a quick break for today's sponsor. Stop me if you've heard this one before. You're wasting your time waiting for builds, which is why you should move to Blacksmith, today's sponsor. I've done this spiel a whole bunch. I use them every day. Blacksmith is great. Cool. You get it. Thankfully, they've given me no guidance on what I'm supposed to say in these ads because they trust me to do them justice. And I'm going to push the limits a bit by telling you all the reasons you should not use Blacksmith. Reason one, you love long build times. Maybe that's when you go to refill your coffee or go to the bathroom. If you really like having build times that take 10 minutes instead of 30 seconds, Blacksmith's going to be terrible and you're going to hate your time using it. Another reason you might just love giving Microsoft money. I get it. I have friends that work at Microsoft and you might work at Microsoft yourself. Maybe you just want them to have way more money. Personally, I like the fact that Blacksmith is 50% cheaper and also takes less than half the time to run. So, it's over a 70% discount for most users. Just me, though. I can relate to this one. If you enjoy when debugging your CI feels like a murder mystery trying to go through all the logs to find the thing you're looking for because search doesn't work. You're going to hate Blacksmith and their awesome observability dashboard, working search logs, and more. It's so much easier to get by that you're going to hate it if you want your job to be hard. And one last thing, if you hate open source, definitely don't use Blacksmith because they're sponsoring a ton of useful open source projects, including the browser I'm using here, Zen, which was built on Blacksmith. If none of this applies to you, you should probably go check out the free trial at soyv.link/blsmith. Shout out to my editor for finding a way to turn this all into a video. By the way, he's probably going to have to pull things out of that 4-hour mess to fit them in here, but I'll do my best to cover things from the top. When I first started building this project, I started with a CLI because I wanted it to be easy to see everything working. Like the original core was just this pattern of model one makes a prompt, two other models respond, all of the models vote. Doing that in a UI and managing all of the connections, everything for it would just not have been pleasant. So, I started by vibe coding yet another CLI. Ignore the logging. I added that during debugging. The main parts here with the prompt, the answers, and all of that, that is all working as expected. Deepseek opened here with the only thing toddlers are unexpectedly good at painting with is. And we get the answers you would expect. Pretty solid overall. One of the things that's made this project so fun is trying to find clever solutions to the problems that these models just can't stop throwing at me throughout the process of building it. And they have thrown a lot of problems at me throughout. One of the first ones was the randomness of this initial prompt. As I was hinting at before, when I first started this, I had a pretty simple system prompt for the original prompt where I would hand a bunch of examples to the model through the system prompt of existing whiplash quotes and example prompts. And what I found is that that fixed set kept causing the models to give like the exact same set of things over and over. I had three times in a row with different models where they were about your grandma. I had four in a row where it was about things in funeral homes. It just wasn't really random. and it sucked. So, I tried a pretty crazy thing for this. The first thing I did was get more than 60 prompts. In fact, we got about 870 of them. Obviously, handing all of these to the model is not going to give us anything of value. So, what I chose to do instead was randomly shuffle them and select 60 or 80 in this case for every single time this runs. So, every model gets a unique system prompt for each run, which results in a unique set of answers, significantly more so than we had prior. And then things are honestly not that bad. The system prompt for the responses is pretty simple. You're playing whiplash. You'll be given a fill-in- thelank prompt. Give the funniest possible answer. Be creative, edgy, unexpected, and concise. Reply only with your answer. No quotes, no explanations, no preamble. Keep it short, under 12 words. Keep it concise and witty. You get the idea. I didn't have to do a lot to format the responses because they randomly put quotes and around. That was a lot of the work honestly. Also, making sure that the result is an actual string, not empty string. So, I could force it to retry in those cases. That ended up being a lot of work, too. Also, cleaning up the vote that they make between A and B, and randomizing which they see as A and which they see as B in order to make sure that works. Also fun challenge, but it all ended up working and eventually I had a CLI that was pretty dang reliable. So, next was the web UI. I originally just had a simple websocket server hosted in bun on railway that you would connect to handle everything like the votes and whatnot in the web UI. But after dealing with utter hell trying to figure out who was who there cuz the IP address spoofing is a very real problem eventually we gave up and did it all through Twitch instead so I could avoid O and whatnot there too. So after everything we've described so far I had a working CLI. I had a working web UI. I had it deployed and mostly functioning. But I wanted to go further because I really wanted to have the Twitch stream. But you can't just send an HTML page to Twitch. You got to stream it somehow. And thankfully, I have a lot of experience doing weird stuff with FFmpeg and streaming to Twitch with it. I had to do a lot of back and forth with a lot of different models to get this working how I wanted it to. The way this is working is by rendering a pixel perfect canvas in the browser with the exact content that I want. So once that browser's been spun up and has that canvas page, which I'm doing is like a headless Chromium instance. A lot of environment variables here that I can pass things to. I need to knock the max bit rate down probably, but we're not even getting close to it, so it's fine. Once we have music, I'll probably have to knock that down. I create the ffmpeg command, which has a lot of fun things. I actually know a lot about streaming to Twitch from FFmpeg because that's how I stream to Twitch when I worked at Twitch for marathon content. I've thought a lot about generative content with ffmpeg streaming"}
{"id": "_k22WAEAfpE", "title": "Anthropic is lying to us.", "snippet": "I'm really not allowed days off anymore, am I? I just wrapped up a bunch of streams and releases over the weekend and the prior week, hoping to take Monday off at least. But, uh, Anthropic is not going to allow that. According to Anthropic, there are three major labs out of China that have been doing distillation attacks on Anthropic's models. They list Deep Seek, who I'm sure you all know, Moonshot, who are the creators of Kimmy, as well as Miniax, the creators of the Miniax models, as companies that are doing distillation attacks against Anthropic. That's a very bold claim, especially the piece here where they say there's over 24,000 fraudulent accounts generating over 16 million exchanges trying to extract these capabilities to bring them to China. Foreign labs that illicitly distill American models can remove safeguards, feeding model capabilities into their own military intelligence and surveillance systems. Oh boy, there's a lot to talk about here. both in the legitimacy of the claims being made, but more importantly going into the potential impacts of what's being discussed here. There's a real problem to talk about here, and as much as I am Anthropic's number one certified hater, I can empathize with parts of what they're thinking here. That said, if you look at the replies, you'll see not many agree. Yeah, I have a lot to say here, and it's probably going to burn relationships with a lot of other companies. So, if I want to keep making a living, we're going to have to take a quick break for today's sponsor. Do you know what Anthropic, OpenAI, Versell, and T3 Chat all have in common? Well, we all like React, but there's something else we're all using, too. Today's sponsor, Work OS. They really get off, especially for people trying to sell to big companies. They've done it themselves, selling to basically every company that I have to sign into the dashboards of. It's kind of crazy just how often I run into the Work OS offkit signin page, and I'm like, \"Huh, not just us.\" Seriously though, everyone's using Work OS and there's a reason why. They have the DX that you would expect from a modern company, but they also have the integrations you would expect from an enterprise first business. If a big company like Microsoft or Bloomberg came to you today and said they wanted to use your product, would you be ready to support them? I know it sounds crazy, but more and more we're seeing these big companies work with earlystage startups. I just heard from a startup that's only 3 weeks in since launch and they already have a Fortune50 company using their product. It's wild how many of these companies are willing to adopt. You have to be able to support them. And if you don't have integration with Octa, SAML, Duo, ADP, or all these other crazy platforms, good luck getting those enterprises assigned. The hell you'll have to deal with going back and forth between the IT team and your engineers is just not worth it when you can send them a link with one click that will handle all of their setup for them. I'll let GMO end this one for me. I think we could have done even more business if we had partnered with works earlier. It's been incredibly wellreceived. Check them out now at swive.link/works. Let's dive into what Anthropic has to say about these distillation attacks. As far as I know, the phrase distillation attack is a novel phrase that Anthropic came up with for this reporting. I've never heard that terminology used before. Please correct me if I'm wrong in the comments if that is a bad claim on my part, but I've never seen anyone refer to this this way. If you're not familiar with the term distillation in this context, we should go back to the original definition, which is to try and extract the main value out of a thing. In this case, what they're referring to with distillation is taking the outputs from smart models and using those to train new models to have similar intelligence. The conversation around distillation started around when DeepSeek blew up with Deepseek R1 because OpenAI claimed that their 01 model was used as a target for similar distillation attempts. If you're not familiar with what made 01 so special, it was the first reasoning model where it wouldn't just output the results, it would also take time to think. It would have a step before the output where it would talk to itself effectively correct mistakes and then finally output a real answer. OpenAI was so scared about other companies using this model to train their own similar models that they made the bold decision to hide that reasoning trace. So when you ran 01, you wouldn't be able to see the reasoning it did. You would only see the result at the end and you'd see effectively it just waiting until it finished the reasoning steps. And part of what made R1 so magical is that it didn't do that. Deepseekar 1 was an openw weight model. So you could see the entirety of the reasoning step before getting the actual response. But that wasn't enough to keep OpenAI from their bold claim that OpenAI models were used in training DeepSeek R1. To be very clear about what OpenAI was saying about this, it was their belief that the DeepSeek team generated a bunch of data they could use for training by asking questions to OpenAI's 01 model, collecting the results, and then feeding that back into their own training data in their own models. This is a common technique for trying to get good behaviors from really smart models into smaller, cheaper models. Anthropic themselves even says this much in their posting, claiming that distillation can absolutely be legitimate. ALabs use it to create smaller and cheaper models for their customers. But again, they're claiming distillation can be legitimate. In fact, I'd argue almost all of it is. This particular claim is a bit bold, as we'll get to in a bit. But they're not the first to claim that there is distillation happening on their stuff by other people. And this is the reason why to this day basically every major lab either hides or meaningfully obuscates the reasoning traces for their models. When you run Gemini 3.1 Pro, the reasoning steps aren't what it's actually doing. They are the reasoning that the model did handed to another model asked to summarize it in order to obuscate the difference between what the model actually did and what people get back. So they can't train on it the same way. Grock does the same thing. GBT 5, 5.1, 5.2 all do the same thing. There is one lab that doesn't do this for their closed weight models though. Anthropic. For various reasons, Anthropic decided when they first introduced reasoning to not obuscate those reasoning traces when you were using the models. That was a really solid decision on their part. Both for me as a developer building on top of their thing so I could see what the model was doing and better steer it if it's getting things wrong, adjust my system, adjust my prompts, adjust my code bases, etc. But it also means the data is more valuable than the data you can get from other labs in order to do this type of reinforcement learning and distilled training. Honestly though, if you have the inputs and the outputs, you can make up the part between, hand that to the model, and be pretty much good. But having all of the data is very helpful, especially when you see the success that these anthropic models are having for these really longunning jobs. If you can collect all of that data and then use it to train something else, that's potentially really valuable. And that's what a lot of these companies have been doing. Both the major labs, but also some of the popular third parties that we've all grown to know and love. As a simple example, Cursor. [snorts] Think about Curser's business model for a second here. Cursor is providing us a really good interface and harness in order to edit and write code using these really fancy models. Cursor is paying API prices for those models, though. So, we're being realistic here. If you pay 20 bucks a month for Cursor and 20 bucks a month for Cloud Code, you're probably going to get much more use out of the Cloud Code sub if you're using Enthropic models because Enthropic will subsidize that $20 a month subscription. Cursor can't really because they have to pay retail price for the actual API calls. But there's a way they can make that worthwhile. What if that data wasn't only used to write"}
